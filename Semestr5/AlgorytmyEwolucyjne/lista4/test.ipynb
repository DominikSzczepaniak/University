{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class CMA(object):\n",
    "    \"\"\"\n",
    "    Covariance Matrix Adaptation Evolution Strategy (CMA-ES) implemented with TensorFlow v2.\n",
    "\n",
    "    This implementation is essentially following \"The CMA Evolution Strategy: A Tutorial\" [1]\n",
    "\n",
    "    [1] https://arxiv.org/abs/1604.00772\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        initial_solution,\n",
    "        initial_step_size,\n",
    "        fitness_function,\n",
    "        enforce_bounds=None,\n",
    "        population_size=None,\n",
    "        cc=None,\n",
    "        cσ=None,\n",
    "        c1=None,\n",
    "        cμ=None,\n",
    "        damps=None,\n",
    "        termination_no_effect=1e-8,\n",
    "        store_trace=False,\n",
    "        callback_function=None,\n",
    "        dtype=tf.float32,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          initial_solution\n",
    "            Search starting point, a list or numpy array.\n",
    "\n",
    "          initial_step_size\n",
    "            Standard deviation of the covariance matrix at generation 0.\n",
    "\n",
    "          fitness_function\n",
    "            Function to be minimized. Function must have the following signature:\n",
    "            ```\n",
    "            Args:\n",
    "              x: tf.Tensor of shape (M, N)\n",
    "\n",
    "            Returns:\n",
    "              Fitness evaluations: tf.Tensor of shape (M,)\n",
    "            ```\n",
    "            Where `M` is the number of solutions to evaluate and `N` is the dimension\n",
    "            of a single solution.\n",
    "\n",
    "          enforce_bounds\n",
    "            2D list, the min and max for each dimension, e.g. [[-1, 1], [-2, 2], [0, 1]].\n",
    "            Ensures the fitness function is never called with out of bounds values.\n",
    "            Out of bounds samples are clipped back to the minimum or maximum values and a penalty\n",
    "            of `||x - x_clipped||` is added to the fitness evaluation.\n",
    "\n",
    "          population_size\n",
    "            Number of samples produced at each generation.\n",
    "            Defaults to 8 + 3 * ln(dimension) (e.g. 10 for 2 dimensions, 14 for 10 dimensions)\n",
    "\n",
    "          cc, cσ, c1, cμ, damps\n",
    "            Core parameters of the algorithm. Set to appropriate values by default.\n",
    "\n",
    "          termination_no_effect\n",
    "            Set the threshold for NoEffectAxis and NoEffectCoord termination criteria.\n",
    "            Decreasing this value can increase the number of significant decimals of the solution.\n",
    "            Defaults to 1e-8.\n",
    "\n",
    "          store_trace\n",
    "            If True, core variables are stored in memory (attribute self.trace) at each generation.\n",
    "            This is mostly a debugging mechanism and it should not be used in production.\n",
    "            Defaults to False.\n",
    "\n",
    "          callback_function\n",
    "            User defined function called first after initialization, then at the end of each\n",
    "            generation. Intended for logging purpose.\n",
    "            Function must have the following signature:\n",
    "            ```\n",
    "            Args:\n",
    "              cma: the parent CMA instance (i.e. self)\n",
    "              logger: a python Logger instance\n",
    "            ```\n",
    "        \"\"\"\n",
    "        if not isinstance(initial_solution, (np.ndarray, list)):\n",
    "            raise ValueError('Initial solution must be a list or numpy array')\n",
    "        elif np.ndim(initial_solution) != 1:\n",
    "            ndim = np.ndim(initial_solution)\n",
    "            raise ValueError(f'Initial solution must be a 1D array but got an array of dim {ndim}')\n",
    "        elif not np.isscalar(initial_step_size) or initial_step_size <= 0:\n",
    "            raise ValueError(f'Initial step size must be a number greater than zero')\n",
    "        elif not callable(fitness_function):\n",
    "            raise ValueError(f'Fitness function must be callable')\n",
    "        elif population_size is not None and population_size <= 4:\n",
    "            raise ValueError(f'Population size must be at least 4')\n",
    "        elif enforce_bounds is not None and not isinstance(enforce_bounds, (np.ndarray, list)):\n",
    "            raise ValueError('Bounds must be a list or numpy array')\n",
    "        elif enforce_bounds is not None and np.ndim(enforce_bounds) != 2:\n",
    "            ndim = np.ndim(enforce_bounds)\n",
    "            raise ValueError(f'Bounds must be a 2D array but got an array of dim {ndim}')\n",
    "        elif callback_function is not None and not callable(callback_function):\n",
    "            raise ValueError(f'Callback function must be callable')\n",
    "\n",
    "        self.generation = 0\n",
    "        self.initial_solution = initial_solution\n",
    "        self.initial_step_size = initial_step_size\n",
    "        self.fitness_fn = fitness_function\n",
    "        self.population_size = population_size\n",
    "        self.enforce_bounds = enforce_bounds\n",
    "        self._cc = cc\n",
    "        self._cσ = cσ\n",
    "        self._c1 = c1\n",
    "        self._cμ = cμ\n",
    "        self._damps = damps\n",
    "        self.termination_no_effect = termination_no_effect\n",
    "        self.store_trace = store_trace\n",
    "        self.callback_fn = callback_function\n",
    "        self.dtype = dtype\n",
    "        self.termination_criterion_met = False\n",
    "\n",
    "        self._initialized = False\n",
    "\n",
    "    def init(self):\n",
    "        if self._initialized:\n",
    "            raise ValueError('Already initialized - call reset method to start over')\n",
    "\n",
    "        self.generation = 0\n",
    "        self.dimension = len(self.initial_solution)\n",
    "        self._enforce_bounds = self.enforce_bounds is not None\n",
    "        self.trace = []\n",
    "\n",
    "        # -------------------------\n",
    "        # Non-trainable parameters\n",
    "        # -------------------------\n",
    "        # Solution dimension\n",
    "        self.N = tf.constant(self.dimension, dtype=self.dtype)\n",
    "        # Population size\n",
    "        if self.population_size is not None:\n",
    "            self.λ = tf.constant(self.population_size, dtype=self.dtype)\n",
    "        else:\n",
    "            self.λ = tf.floor(tf.math.log(self.N) * 3 + 8)\n",
    "        # Shape of the population of solutions\n",
    "        print(\"λ = \", self.λ)\n",
    "        self.shape = tf.cast((self.λ, self.N), tf.int32)\n",
    "        # Number of surviving individuals from one generation to the next\n",
    "        self.μ = tf.floor(self.λ / 2)\n",
    "        # Recombination weights\n",
    "        self.weights = tf.concat([\n",
    "            tf.math.log(self.μ + 0.5) - tf.math.log(tf.range(1, self.μ + 1)),\n",
    "            tf.zeros(shape=(self.λ - self.μ,), dtype=self.dtype),\n",
    "        ], axis=0)\n",
    "        # Normalize weights such as they sum to one and reshape into a column matrix\n",
    "        self.weights = (self.weights / tf.reduce_sum(self.weights))[:, tf.newaxis]\n",
    "        print(\"weights shape= \", self.weights.shape)\n",
    "        # Variance-effective size of mu\n",
    "        self.μeff = tf.reduce_sum(self.weights) ** 2 / tf.reduce_sum(self.weights ** 2)\n",
    "        # Time constant for cumulation for C\n",
    "        if self._cc is not None:\n",
    "            self.cc = tf.constant(self._cc, dtype=self.dtype)\n",
    "        else:\n",
    "            self.cc = (4 + self.μeff / self.N) / (self.N + 4 + 2 * self.μeff / self.N)\n",
    "        # Time constant for cumulation for sigma control\n",
    "        if self._cσ is not None:\n",
    "            self.cσ = tf.constant(self._cσ, dtype=self.dtype)\n",
    "        else:\n",
    "            self.cσ = (self.μeff + 2) / (self.N + self.μeff + 5)\n",
    "        # Learning rate for rank-one update of C\n",
    "        if self._c1 is not None:\n",
    "            self.c1 = tf.constant(self._c1, dtype=self.dtype)\n",
    "        else:\n",
    "            self.c1 = 2 / ((self.N + 1.3)**2 + self.μeff)\n",
    "        # Learning rate for rank-μ update of C\n",
    "        if self._cμ is not None:\n",
    "            self.cμ = tf.constant(self._cμ, dtype=self.dtype)\n",
    "        else:\n",
    "            self.cμ = 2 * (self.μeff - 2 + 1 / self.μeff) / ((self.N + 2)**2 + 2 * self.μeff / 2)\n",
    "        # Damping for sigma\n",
    "        if self._damps is not None:\n",
    "            self.damps = tf.constant(self._damps, dtype=self.dtype)\n",
    "        else:\n",
    "            self.damps = (\n",
    "                1 + 2 * tf.maximum(0, tf.sqrt((self.μeff - 1) / (self.N + 1)) - 1) + self.cσ\n",
    "            )\n",
    "        # Expectation of ||N(0,I)||\n",
    "        self.chiN = tf.sqrt(self.N) * (1 - 1 / (4 * self.N) + 1 / (21 * self.N**2))\n",
    "\n",
    "        # Define bounds in a format that can be fed to tf.clip_by_value\n",
    "        if self._enforce_bounds:\n",
    "            bounds = tf.convert_to_tensor(self.enforce_bounds, dtype=self.dtype)\n",
    "            self.clip_value_min = bounds[:, 0]\n",
    "            self.clip_value_max = bounds[:, 1]\n",
    "\n",
    "        # ---------------------\n",
    "        # Trainable parameters\n",
    "        # ---------------------\n",
    "        # Mean\n",
    "        self.m = tf.Variable(tf.constant(self.initial_solution, dtype=self.dtype))\n",
    "        print(\"m shape =\", self.m.shape)\n",
    "        # Step-size\n",
    "        self.σ = tf.Variable(tf.constant(self.initial_step_size, dtype=self.dtype))\n",
    "        # Covariance matrix\n",
    "        self.C = tf.Variable(tf.eye(num_rows=self.N, dtype=self.dtype))\n",
    "        # Evolution path for σ\n",
    "        self.p_σ = tf.Variable(tf.zeros((self.N,), dtype=self.dtype))\n",
    "        # Evolution path for C\n",
    "        self.p_C = tf.Variable(tf.zeros((self.N,), dtype=self.dtype))\n",
    "        # Coordinate system (normalized eigenvectors)\n",
    "        self.B = tf.Variable(tf.eye(num_rows=self.N, dtype=self.dtype))\n",
    "        # Scaling (square root of eigenvalues)\n",
    "        self.D = tf.Variable(tf.eye(num_rows=self.N, dtype=self.dtype))\n",
    "\n",
    "        self._initialized = True\n",
    "        return self\n",
    "\n",
    "    def search(self, max_generations=500):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          max_generations\n",
    "            Maximum number of generations to run for. The search can be interrupted before the\n",
    "            max is reached if one of the termination criteria is met.\n",
    "\n",
    "        Returns:\n",
    "          The best solution and its fitness score.\n",
    "        \"\"\"\n",
    "        if not self._initialized:\n",
    "            self.init()\n",
    "\n",
    "        # Call user defined function at generation 0\n",
    "        if self.callback_fn is not None:\n",
    "            self.callback_fn(self, logger)\n",
    "\n",
    "        for _ in range(max_generations):\n",
    "            self.generation += 1\n",
    "\n",
    "            # -----------------------------------------------------\n",
    "            # (1) Sample a new population of solutions ∼ N(m, σ²C)\n",
    "            # -----------------------------------------------------\n",
    "            z = tf.random.normal(self.shape, dtype=self.dtype)   # ∼ N(0, I)\n",
    "            y = tf.matmul(z, tf.matmul(self.B, self.D))          # ∼ N(0, C)\n",
    "            x = self.m + self.σ * y                              # ∼ N(m, σ²C)\n",
    "\n",
    "            penalty = 0.\n",
    "            if self._enforce_bounds:\n",
    "                x_corr = tf.clip_by_value(x, self.clip_value_min, self.clip_value_max)\n",
    "                penalty = tf.norm(x - x_corr)**2\n",
    "                x = x_corr\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # (2) Selection and Recombination: Moving the Mean\n",
    "            # -------------------------------------------------\n",
    "            # Evaluate and sort solutions\n",
    "            f_x = self.fitness_fn(x) + penalty\n",
    "            self.x_sorted = tf.gather(x, tf.argsort(f_x))\n",
    "\n",
    "            if self.store_trace:\n",
    "                self._store_trace()\n",
    "\n",
    "            # The new mean is a weighted average of the top-μ solutions\n",
    "            x_diff = (self.x_sorted - self.m)\n",
    "            x_mean = tf.reduce_sum(tf.multiply(x_diff, self.weights), axis=0)\n",
    "            m = self.m + x_mean\n",
    "\n",
    "            # -----------------------------------\n",
    "            # (3) Adapting the Covariance Matrix\n",
    "            # -----------------------------------\n",
    "            # Udpdate evolution path for Rank-one-Update\n",
    "            y_mean = x_mean / self.σ\n",
    "            p_C = (\n",
    "                (1 - self.cc) * self.p_C +\n",
    "                tf.sqrt(self.cc * (2 - self.cc) * self.μeff) * y_mean\n",
    "            )\n",
    "            p_C_matrix = p_C[:, tf.newaxis]\n",
    "\n",
    "            # Compute Rank-μ-Update\n",
    "            C_m = tf.map_fn(\n",
    "                fn=lambda e: e * tf.transpose(e),\n",
    "                elems=(x_diff / self.σ)[:, tf.newaxis],\n",
    "            )\n",
    "            # print(\"CM shape = \", C_m.shape)\n",
    "            # print(\"weights shape = \", self.weights[:, tf.newaxis].shape)      \n",
    "            y_s = tf.reduce_sum(tf.multiply(C_m, self.weights[:, tf.newaxis]), axis=0)\n",
    "\n",
    "            # Combine Rank-one-Update and Rank-μ-Update\n",
    "            C = (\n",
    "                (1 - self.c1 - self.cμ) * self.C +\n",
    "                self.c1 * p_C_matrix * tf.transpose(p_C_matrix) +\n",
    "                self.cμ * y_s\n",
    "            )\n",
    "\n",
    "            # Enforce symmetry of the covariance matrix\n",
    "            C_upper = tf.linalg.band_part(C, 0, -1)\n",
    "            C_upper_no_diag = C_upper - tf.linalg.tensor_diag(tf.linalg.diag_part(C_upper))\n",
    "            C = C_upper + tf.transpose(C_upper_no_diag)\n",
    "\n",
    "            # ----------------------\n",
    "            # (4) Step-size control\n",
    "            # ----------------------\n",
    "            # Update evolution path for sigma\n",
    "            D_inv = tf.linalg.tensor_diag(tf.math.reciprocal(tf.linalg.diag_part(self.D)))\n",
    "            C_inv_squared = tf.matmul(tf.matmul(self.B, D_inv), tf.transpose(self.B))\n",
    "            # print(\"C_inv_squared shape = \", C_inv_squared.shape)\n",
    "            # print(\"y_mean shape = \", y_mean.shape)\n",
    "            # print(\"b shape = \", self.B.shape)\n",
    "            # print(\"D shape = \", self.D.shape)\n",
    "            C_inv_squared_y = tf.squeeze(tf.matmul(C_inv_squared, y_mean[:, tf.newaxis]))\n",
    "            p_σ = (\n",
    "                (1 - self.cσ) * self.p_σ +\n",
    "                tf.sqrt(self.cσ * (2 - self.cσ) * self.μeff) * C_inv_squared_y\n",
    "            )\n",
    "\n",
    "            # Update sigma\n",
    "            σ = self.σ * tf.exp((self.cσ / self.damps) * ((tf.norm(p_σ) / self.chiN) - 1))\n",
    "\n",
    "            # ----------------------------------------\n",
    "            # (5) Update B and D: eigen decomposition\n",
    "            # ----------------------------------------\n",
    "            u, B, _ = tf.linalg.svd(C)\n",
    "\n",
    "            diag_D = tf.sqrt(u)\n",
    "            D = tf.linalg.tensor_diag(diag_D)\n",
    "\n",
    "            # -------------------------------\n",
    "            # (6) Assign new variable values\n",
    "            # -------------------------------\n",
    "            # Cache computations necessary to determine termination criteria\n",
    "            self._prev_sigma = tf.identity(self.σ)\n",
    "            self._prev_D = tf.identity(self.D)\n",
    "            self._diag_D = diag_D\n",
    "\n",
    "            # Assign values\n",
    "            self.p_C.assign(p_C)\n",
    "            self.p_σ.assign(p_σ)\n",
    "            self.C.assign(C)\n",
    "            self.σ.assign(σ)\n",
    "            self.B.assign(B)\n",
    "            self.D.assign(D)\n",
    "            self.m.assign(m)\n",
    "\n",
    "            # ---------------------------------\n",
    "            # (7) Terminate early if necessary\n",
    "            # ---------------------------------\n",
    "            self.termination_criterion_met = self.should_terminate()\n",
    "\n",
    "            # Call user defined function last\n",
    "            if self.callback_fn is not None:\n",
    "                self.callback_fn(self, logger)\n",
    "\n",
    "            if self.termination_criterion_met:\n",
    "                break\n",
    "\n",
    "        return self.best_solution(), self.best_fitness()\n",
    "\n",
    "    def best_solution(self):\n",
    "        return self.m.read_value().numpy()\n",
    "\n",
    "    def best_fitness(self):\n",
    "        return self.fitness_fn(tf.stack([self.m])).numpy()[0]\n",
    "\n",
    "    def should_terminate(self, return_details=False):\n",
    "        # NoEffectAxis: stop if adding a 0.1-standard deviation vector in any principal axis\n",
    "        # direction of C does not change m\n",
    "        i = self.generation % self.dimension\n",
    "        m_nea = self.m + 0.1 * self.σ * tf.squeeze(self._diag_D[i] * self.B[i,:])\n",
    "        m_nea_diff = tf.abs(self.m - m_nea)\n",
    "        no_effect_axis = tf.reduce_all(tf.less(m_nea_diff, self.termination_no_effect))\n",
    "\n",
    "        # NoEffectCoord: stop if adding 0.2 stdev in any single coordinate does not change m\n",
    "        m_nec = self.m + 0.2 * self.σ * tf.linalg.diag_part(self.C)\n",
    "        m_nec_diff = tf.abs(self.m - m_nec)\n",
    "        no_effect_coord = tf.reduce_any(tf.less(m_nec_diff, self.termination_no_effect))\n",
    "\n",
    "        # ConditionCov: stop if the condition number of the covariance matrix becomes too large\n",
    "        max_D = tf.reduce_max(self._diag_D)\n",
    "        min_D = tf.reduce_min(self._diag_D)\n",
    "        condition_number = max_D**2 / min_D**2\n",
    "        condition_cov = tf.greater(condition_number, 1e14)\n",
    "\n",
    "        # TolXUp: stop if σ × max(D) increased by more than 10^4.\n",
    "        # This usually indicates a far too small initial σ, or divergent behavior.\n",
    "        prev_max_D = tf.reduce_max(tf.linalg.diag_part(self._prev_D))\n",
    "        tol_x_up_diff = tf.abs(self.σ * max_D - self._prev_sigma * prev_max_D)\n",
    "        tol_x_up = tf.greater(tol_x_up_diff, 1e4)\n",
    "\n",
    "        do_terminate = no_effect_axis or no_effect_coord or condition_cov or tol_x_up\n",
    "\n",
    "        if not return_details:\n",
    "            return do_terminate\n",
    "        else:\n",
    "            return (\n",
    "                do_terminate,\n",
    "                dict(\n",
    "                    no_effect_axis=bool(no_effect_axis.numpy()),\n",
    "                    no_effect_coord=bool(no_effect_coord.numpy()),\n",
    "                    condition_cov=bool(condition_cov.numpy()),\n",
    "                    tol_x_up=bool(tol_x_up.numpy()),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def reset(self):\n",
    "        self._initialized = False\n",
    "        return self.init()\n",
    "\n",
    "    def _store_trace(self):\n",
    "        self.trace.append({\n",
    "            'm': self.m.read_value().numpy(),\n",
    "            'σ': self.σ.read_value().numpy(),\n",
    "            'C': self.C.read_value().numpy(),\n",
    "            'p_σ': self.p_σ.read_value().numpy(),\n",
    "            'p_C': self.p_C.read_value().numpy(),\n",
    "            'B': self.B.read_value().numpy(),\n",
    "            'D': self.D.read_value().numpy(),\n",
    "            'population': self.x_sorted.numpy(),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ =  tf.Tensor(20.0, shape=(), dtype=float64)\n",
      "weights shape=  (20, 1)\n",
      "m shape = (50,)\n",
      "[ 196.24658469  208.98649462  -11.18168483  208.89673367 -125.17523022\n",
      "  187.71023508  200.85501705  193.99321894  200.01568119   56.18380705\n",
      " -130.8844714   202.49683075  204.01823182 -114.28051466  212.4705206\n",
      "  212.85422741  225.58970052  196.61745865  204.72200997  209.01065653\n",
      "   64.13035424  198.06053775  207.5659289   205.73179304  203.93962725\n",
      "  192.62602865  185.42738521  418.25315297   41.78481784    6.42704487\n",
      "   50.64823748  206.77988332  -36.4101947   212.08934676   61.96061719\n",
      " -119.3656184   205.67837202  190.33900933   -5.64027012  -16.16552405\n",
      " -114.32143066  205.80045361  198.87856527  204.52933999  198.74379053\n",
      "  187.96028133   62.63819658  211.30608387  197.52463365  -14.99022677]\n",
      "13470.044461822472\n"
     ]
    }
   ],
   "source": [
    "num_max_epochs = 100\n",
    "\n",
    "def sphere(x):\n",
    "    \"\"\"\n",
    "    Sphere Function\n",
    "    https://www.sfu.ca/~ssurjano/spheref.html\n",
    "    \"\"\"\n",
    "    return tf.reduce_sum(x**2, axis=1)\n",
    "\n",
    "def schwefel(x):\n",
    "    \"\"\"\n",
    "    Schwefel Function\n",
    "    https://www.sfu.ca/~ssurjano/schwef.html\n",
    "    \"\"\"\n",
    "    dimension = tf.cast(tf.shape(x)[1], tf.float64)\n",
    "    return 418.9829 * dimension - tf.reduce_sum(x * tf.sin(tf.sqrt(tf.abs(x))), axis=1)\n",
    "dim = 50\n",
    "cma = CMA(\n",
    "    initial_solution=[100.] * dim,\n",
    "    initial_step_size=50.,\n",
    "    fitness_function=schwefel,\n",
    "    # Test setting the population and enforcing the bounds:\n",
    "    population_size=20,\n",
    "    enforce_bounds=[[-500, 500]] * dim,\n",
    "    dtype=tf.float64,\n",
    ")\n",
    "cma.search(num_max_epochs)\n",
    "\n",
    "x1 = cma.best_solution()\n",
    "fval = cma.best_fitness()\n",
    "print(x1)\n",
    "print(fval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
