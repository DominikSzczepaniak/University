{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominik/Desktop/University/Semestr5/ModeleJezykowe/.env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "polka = pipeline(\"text-generation\", model=\"eryk-mazus/polka-1.1b\")\n",
    "model = polka.model \n",
    "tokenizer = polka.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_math_question(question):\n",
    "    math_keywords = ['ile to jest', 'oblicz', 'jaki jest wynik', 'policz', 'wykonaj działanie']\n",
    "    return any(keyword in question.lower() for keyword in math_keywords)\n",
    "\n",
    "def answer_math_question(question):\n",
    "    try:\n",
    "        patterns = [\n",
    "            r'ile to jest (.*)\\?',\n",
    "            r'oblicz (.*)\\.',\n",
    "            r'jaki jest wynik (.*)\\?',\n",
    "            r'policz (.*)\\.',\n",
    "            r'wykonaj działanie (.*)\\.'\n",
    "        ]\n",
    "        expression = None\n",
    "        for pattern in patterns:\n",
    "            match = re.findall(pattern, question.lower())\n",
    "            if match:\n",
    "                expression = match[0]\n",
    "                break\n",
    "        if expression is None:\n",
    "            return \"Nie potrafię znaleźć wyrażenia do obliczenia.\"\n",
    "        # Zamiana słów na operatory\n",
    "        expression = expression.replace('plus', '+').replace('minus', '-').replace('razy', '*')\\\n",
    "                               .replace('podzielić przez', '/').replace('podzielone przez', '/')\\\n",
    "                               .replace(' ', '')\n",
    "        # Bezpieczne obliczenie wyrażenia\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except Exception:\n",
    "        return \"Nie potrafię obliczyć tego wyrażenia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_translation_question(question):\n",
    "    translation_keywords = ['jak po polsku jest', 'co oznacza', 'przetłumacz', 'jak przetłumaczyć']\n",
    "    return any(keyword in question.lower() for keyword in translation_keywords)\n",
    "\n",
    "def answer_translation_question(question):\n",
    "    patterns = [\n",
    "        r'co oznacza (.*) po polsku\\?',\n",
    "        r'jak po polsku jest (.*)\\?',\n",
    "        r'przetłumacz (.*)\\.',\n",
    "        r'jak przetłumaczyć (.*) na polski\\?'\n",
    "    ]\n",
    "    word = None\n",
    "    for pattern in patterns:\n",
    "        match = re.findall(pattern, question.lower())\n",
    "        if match:\n",
    "            word = match[0].strip().strip(\"'\\\"\")\n",
    "            break\n",
    "    if word:\n",
    "        possible_translations = ['kot', 'pies', 'dom', 'samochód', 'drzewo']\n",
    "        best_translation = ''\n",
    "        best_score = float('-inf')\n",
    "        for translation in possible_translations:\n",
    "            input_text = f\"Słowo '{word}' oznacza po polsku '{translation}'.\"\n",
    "            inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                log_probs = torch.nn.functional.log_softmax(outputs.logits, dim=-1)\n",
    "                log_probs = log_probs[:, :-1, :]\n",
    "                target_tokens = inputs[:, 1:]\n",
    "                log_probs_target = log_probs.gather(2, target_tokens.unsqueeze(-1)).squeeze(-1)\n",
    "                score = log_probs_target.sum().item()\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_translation = translation\n",
    "        return best_translation if best_translation else \"Nie znam tłumaczenia.\"\n",
    "    else:\n",
    "        return \"Nie potrafię przetłumaczyć tego słowa.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    if is_math_question(question):\n",
    "        return answer_math_question(question)\n",
    "    elif is_translation_question(question):\n",
    "        return answer_translation_question(question)\n",
    "    else:\n",
    "        inputs = tokenizer.encode(question + \" Odpowiedź:\", return_tensors='pt')\n",
    "        outputs = model.generate(inputs, max_new_tokens=80, num_return_sequences=1)\n",
    "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        return answer.replace(question + \" Odpowiedź:\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Ile to jest 7 razy 8?\n",
      "Odpowiedź: 56\n",
      "\n",
      "Pytanie: Oblicz 15 plus 27.\n",
      "Odpowiedź: 42\n",
      "\n",
      "Pytanie: Jaki jest wynik 9 podzielone przez 3?\n",
      "Odpowiedź: 3.0\n",
      "\n",
      "Pytanie: Policz 12 minus 5.\n",
      "Odpowiedź: 7\n",
      "\n",
      "Pytanie: Wykonaj działanie 6 razy 7.\n",
      "Odpowiedź: 42\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jak po polsku jest 'cat'?\n",
      "Odpowiedź: kot\n",
      "\n",
      "Pytanie: Co oznacza 'dog' po polsku?\n",
      "Odpowiedź: pies\n",
      "\n",
      "Pytanie: Przetłumacz 'house'.\n",
      "Odpowiedź: dom\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jak przetłumaczyć 'tree' na polski?\n",
      "Odpowiedź: drzewo\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jaka jest stolica Francji?\n",
      "Odpowiedź: Paryż! | Blog podróżniczy\\n Paryż!\\nFrancja to kraj, który koj\n",
      "\n",
      "Pytanie: Kto jest prezydentem Polski?\n",
      "Odpowiedź: Andrzej Duda - WP Wiadomości\\n Andrzej Duda\\nAndrzej Duda został wybrany na prezy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Ile to jest 7 razy 8?\",\n",
    "    \"Oblicz 15 plus 27.\",\n",
    "    \"Jaki jest wynik 9 podzielone przez 3?\",\n",
    "    \"Policz 12 minus 5.\",\n",
    "    \"Wykonaj działanie 6 razy 7.\",\n",
    "    \"Jak po polsku jest 'cat'?\",\n",
    "    \"Co oznacza 'dog' po polsku?\",\n",
    "    \"Przetłumacz 'house'.\",\n",
    "    \"Jak przetłumaczyć 'tree' na polski?\",\n",
    "    \"Jaka jest stolica Francji?\",\n",
    "    \"Kto jest prezydentem Polski?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    answer = generate_answer(question)\n",
    "    print(\"Pytanie:\", question)\n",
    "    print(\"Odpowiedź:\", answer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Która organizacja powstała wcześniej: Europejska Wspólnota Węgla i Stali czy Europejska Wspólnota Energii Atomowej?\n",
      "Oczekiwana odpowiedź: Europejska Wspólnota Węgla i Stali\n",
      "Wygenerowana odpowiedź: Europejska Wspólnota Energii Atomowej, która powstała w 1957 r. w wyniku połączenia Europejskiej Wspólnoty Węgla i Stali oraz Europejskiej Wspólnoty Energii Atomowej. Europejska Wspólnota Energii Atomowej została powołana w celu st\n",
      "Niepoprawna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: W którym wieku został odlany dzwon Zygmunta?\n",
      "Oczekiwana odpowiedź: w XVI\t16\n",
      "Wygenerowana odpowiedź: 100 lat temu - Dziennik Wschodni\\n 100 lat temu\\n100 lat temu odlano pierwszy dzwon Zygmunta w Lublinie. (fot. archiwum)\\n100 lat temu odl\n",
      "Niepoprawna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Czy przymiotniki odmienia się przez przypadki?\n",
      "Oczekiwana odpowiedź: tak\n",
      "Wygenerowana odpowiedź: nie - JakSięPisze.pl\\n nie\\nJeden komentarz do “ nie”?\\nCelem dla którego powstała niniejsza publikacja było merytoryczne om\n",
      "Niepoprawna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jak z łaciny nazywa się dowód sądowy polegający na wykazaniu, że osoba oskarżona nie przebywała na miejscu przestępstwa w chwili gdy je popełniono?\n",
      "Oczekiwana odpowiedź: alibi\n",
      "Wygenerowana odpowiedź: dowód z zeznań świadków, którzy zeznali, że oskarżony był w miejscu przestępstwa i że nie przebywał tam w chwili gdy popełniono przestępstwo. Dowód ten jest dowodem na przestępstwo, a nie dowodem na to, że oskarżony był w miejs\n",
      "Niepoprawna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jak brzmi nazwa terenowej Łady?\n",
      "Oczekiwana odpowiedź: Niva\n",
      "Wygenerowana odpowiedź: Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada, Łada\n",
      "Niepoprawna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Z którego kontynentu pochodzi 90% światowej produkcji ryżu?\n",
      "Oczekiwana odpowiedź: z Azji\n",
      "Wygenerowana odpowiedź: z Indii! - Sputnik Polska\\n10:00 16.01.2021 (zaktualizowano 10:02 16.01.2021) Krótki link\\nIndie są największym producentem ryżu na świecie, a ich produkcja wynosi 100\n",
      "Niepoprawna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jak nazywają się boczne pasy na mundurowych spodniach?\n",
      "Oczekiwana odpowiedź: lampasy\n",
      "Wygenerowana odpowiedź: to kieszenie na broń!\\nKieszenie na broń to nie tylko kieszenie na broń, ale także kieszenie na inne rzeczy, takie jak klucze, telefon, portfel, czy nawet pieniądze. Ale czy wiesz, że kieszenie na broń są również nazywane boczne pasy na mundu\n",
      "Niepoprawna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jak nazywał się gigantyczny goryl, bohater filmów japońskich?\n",
      "Oczekiwana odpowiedź: King Kong\n",
      "Wygenerowana odpowiedź: „Kamikaze” | naTemat.pl\\n „Kamikaze” •\\n „Kamikaze”\\nJak nazywał się gig\n",
      "Niepoprawna\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jak nazywa się pojedynczy element schodów oraz cyfrowa ocena postępów ucznia?\n",
      "Oczekiwana odpowiedź: stopień\n",
      "Wygenerowana odpowiedź: to jest to, co nazywamy schodami. Schody są jednym z najbardziej popularnych przedmiotów do nauki, ponieważ są one bardzo łatwe do nauczenia się i są bardzo łatwe do nauczenia się. Ponadto, schody są bardzo łatwe do nauczenia się i są bardzo\n",
      "Niepoprawna\n",
      "\n",
      "Pytanie: Który kolumbijski pisarz urodzony w 1927 roku jest autorem powieści „Sto lat samotności”?\n",
      "Oczekiwana odpowiedź: Gabriel García Márquez\tMárquez\n",
      "Wygenerowana odpowiedź: „Papierowy anioł”.\\n1. „Papierowy anioł” to powieść o tym, jak w czasach wojny domowej w Kolumbii, 1948 roku, młody chłopak, Juan Carlos, trafia do więzienia i tam poznaje tajemniczą dziewczynę, która naz\n",
      "Niepoprawna\n",
      "\n",
      "Accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_answers(question_file, answer_file, limit = None):\n",
    "    with open(question_file, 'r', encoding='utf-8') as qf, open(answer_file, 'r', encoding='utf-8') as af:\n",
    "        questions = qf.readlines()\n",
    "        answers = af.readlines()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for question, expected_answer in zip(questions, answers):\n",
    "        if limit is not None and total >= limit:\n",
    "            break\n",
    "        total += 1\n",
    "        question = question.strip()\n",
    "        expected_answer = expected_answer.strip()\n",
    "        \n",
    "        generated_answer = generate_answer(question).strip()\n",
    "\n",
    "        if generated_answer.lower() == expected_answer.lower():\n",
    "            correct += 1\n",
    "\n",
    "        print(f\"Pytanie: {question}\")\n",
    "        print(f\"Oczekiwana odpowiedź: {expected_answer}\")\n",
    "        print(f\"Wygenerowana odpowiedź: {generated_answer}\")\n",
    "        print(f\"{'Poprawna' if generated_answer.lower() == expected_answer.lower() else 'Niepoprawna'}\\n\")\n",
    "    \n",
    "    accuracy = correct / total * 100 if total > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "evaluate_answers(\"task4_questions.txt\", \"task4_answers.txt\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
